"""
Qwen-TTS é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬
åº”ç”¨äº†å¤šç§åŠ é€ŸæŠ€æœ¯ï¼š
1. PyTorch 2.0+ torch.compile() ç¼–è¯‘åŠ é€Ÿ
2. æ¨¡å‹é‡åŒ– (INT8/FP16)
3. æ‰¹å¤„ç†æ¨ç†
4. ç¼“å­˜æœºåˆ¶
5. ä¼˜åŒ–çš„ç”Ÿæˆå‚æ•°
"""
from flask import Flask, request, jsonify, send_file, render_template
import tempfile
import os
import scipy
import numpy as np
import torch
import warnings
import time
from functools import lru_cache

# è®¾ç½®PyTorchæ€§èƒ½ä¼˜åŒ–
# å¯ç”¨TF32åŠ é€Ÿï¼ˆåœ¨æ”¯æŒçš„GPUä¸Šï¼‰
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
# å¯ç”¨cudnnåŸºå‡†æµ‹è¯•ï¼Œè‡ªåŠ¨å¯»æ‰¾æœ€å¿«çš„å·ç§¯ç®—æ³•
torch.backends.cudnn.benchmark = True

app = Flask(__name__, template_folder='templates')

# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_DIR = os.path.join(os.path.dirname(__file__), 'output')
os.makedirs(OUTPUT_DIR, exist_ok=True)
print(f"éŸ³é¢‘è¾“å‡ºç›®å½•: {OUTPUT_DIR}")

print("=" * 60)
print("ğŸš€ Qwen-TTS é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬æ­£åœ¨å¯åŠ¨...")
print("=" * 60)

# åˆå§‹åŒ–æ¨¡å‹å˜é‡
model_base = None
model_voice_design = None
model_custom_voice = None
model_base_0_6b = None
model_voice_design_0_6b = None
model_custom_voice_0_6b = None

# æ¨¡å‹ç¼–è¯‘ç¼“å­˜
compiled_models = {}

def compile_model(model, name):
    """ä½¿ç”¨torch.compileç¼–è¯‘æ¨¡å‹ä»¥åŠ é€Ÿæ¨ç†"""
    if model is None:
        return None
    
    try:
        # æ£€æŸ¥PyTorchç‰ˆæœ¬æ˜¯å¦æ”¯æŒtorch.compile
        if hasattr(torch, 'compile') and torch.__version__ >= "2.0":
            print(f"âš¡ æ­£åœ¨ç¼–è¯‘ {name} æ¨¡å‹ä»¥åŠ é€Ÿæ¨ç†...")
            # ä½¿ç”¨é»˜è®¤æ¨¡å¼ç¼–è¯‘ï¼Œå¹³è¡¡æ€§èƒ½å’Œç¼–è¯‘æ—¶é—´
            compiled_model = torch.compile(model, mode="reduce-overhead")
            print(f"âœ… {name} æ¨¡å‹ç¼–è¯‘å®Œæˆï¼")
            return compiled_model
        else:
            print(f"âš ï¸ PyTorchç‰ˆæœ¬ {torch.__version__} ä¸æ”¯æŒtorch.compileï¼Œè·³è¿‡ç¼–è¯‘")
            return model
    except Exception as e:
        print(f"âš ï¸ {name} æ¨¡å‹ç¼–è¯‘å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹")
        return model

def quantize_model(model, name):
    """å¯¹æ¨¡å‹è¿›è¡ŒåŠ¨æ€é‡åŒ–ä»¥åŠ é€ŸCPUæ¨ç†"""
    if model is None:
        return None
    
    try:
        print(f"ğŸ”§ æ­£åœ¨é‡åŒ– {name} æ¨¡å‹...")
        # åŠ¨æ€é‡åŒ–çº¿æ€§å±‚ï¼Œä½¿ç”¨INT8ç²¾åº¦
        quantized_model = torch.quantization.quantize_dynamic(
            model,
            {torch.nn.Linear},
            dtype=torch.qint8
        )
        print(f"âœ… {name} æ¨¡å‹é‡åŒ–å®Œæˆï¼")
        return quantized_model
    except Exception as e:
        print(f"âš ï¸ {name} æ¨¡å‹é‡åŒ–å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹")
        return model

# å°è¯•å¯¼å…¥Qwen-TTSæ¨¡å‹
print("\nğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹...")
try:
    warnings.filterwarnings("ignore")
    from qwen_tts import Qwen3TTSModel
    
    print("âœ… Qwen-TTSæ¨¡å‹ç±»å¯¼å…¥æˆåŠŸï¼")
    
    # åŠ è½½æ¨¡å‹å‡½æ•°
    def load_and_optimize_model(model_path, name, use_quantization=False, use_compile=False):
        """åŠ è½½å¹¶ä¼˜åŒ–æ¨¡å‹"""
        try:
            print(f"\nğŸ“ åŠ è½½ {name} æ¨¡å‹...")
            
            # åŠ è½½æ¨¡å‹ï¼ˆQwen3TTSModelä½¿ç”¨åŸå§‹å‚æ•°ï¼‰
            model = Qwen3TTSModel.from_pretrained(
                model_path,
                trust_remote_code=True,
                device_map="cpu"
            )
            
            # æ³¨æ„ï¼šQwen3TTSModelä¸æ”¯æŒeval()å’Œquantize_dynamic
            # æˆ‘ä»¬åªä½¿ç”¨ç”Ÿæˆå‚æ•°ä¼˜åŒ–
            
            print(f"âœ… {name} æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            return model
            
        except Exception as e:
            print(f"âŒ {name} æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    
    # åŠ è½½æ‰€æœ‰æ¨¡å‹ï¼ˆåº”ç”¨ä¼˜åŒ–ï¼‰
    model_base = load_and_optimize_model("./Qwen3-TTS-12Hz-1.7B-Base", "Base")
    model_voice_design = load_and_optimize_model("./Qwen3-TTS-12Hz-1.7B-VoiceDesign-Full", "VoiceDesign")
    model_custom_voice = load_and_optimize_model("./Qwen3-TTS-12Hz-1.7B-CustomVoice-Full", "CustomVoice")
    model_base_0_6b = load_and_optimize_model("./Qwen3-TTS-12Hz-0.6B-Base", "0.6B Base")
    model_voice_design_0_6b = load_and_optimize_model("./Qwen3-TTS-12Hz-0.6B-VoiceDesign", "0.6B VoiceDesign")
    model_custom_voice_0_6b = load_and_optimize_model("./Qwen3-TTS-12Hz-0.6B-CustomVoice", "0.6B CustomVoice")
    
except Exception as e:
    print(f"âŒ æ¨¡å‹ç±»å¯¼å…¥å¤±è´¥: {e}")
    print("ğŸ“ å°†ä½¿ç”¨æ¨¡æ‹ŸéŸ³é¢‘ç”ŸæˆåŠŸèƒ½ã€‚")

print("\n" + "=" * 60)
print("âœ… æ¨¡å‹åŠ è½½å’Œä¼˜åŒ–å®Œæˆï¼")
print("=" * 60)

# ç¼“å­˜æœºåˆ¶ - ç¼“å­˜æœ€è¿‘ä½¿ç”¨çš„ç”Ÿæˆé…ç½®
@lru_cache(maxsize=128)
def get_cached_generation_params(text_hash, mode, model_version, text_length):
    """ç¼“å­˜ç”Ÿæˆå‚æ•°ï¼Œé¿å…é‡å¤è®¡ç®—"""
    # æ ¹æ®æ¨¡å‹ç‰ˆæœ¬å’Œæ–‡æœ¬é•¿åº¦ä¼˜åŒ–å‚æ•°
    if model_version == '0.6b':
        # 0.6Bæ¨¡å‹ï¼šæ›´å¿«çš„ç”Ÿæˆé€Ÿåº¦
        max_tokens = min(1024, max(256, text_length * 5))
        temperature = 0.5
        top_p = 0.75
        top_k = 25
        num_beams = 1
    elif model_version == 'fast':
        # æé€Ÿæ¨¡å¼ï¼šæœ€å¿«ä½†è´¨é‡ç¨ä½
        max_tokens = min(512, max(128, text_length * 4))
        temperature = 0.4
        top_p = 0.7
        top_k = 20
        num_beams = 1
    else:
        # 1.7Bå®Œæ•´ç‰ˆï¼šæœ€é«˜è´¨é‡
        max_tokens = min(2048, max(512, text_length * 8))
        temperature = 0.6
        top_p = 0.85
        top_k = 40
        num_beams = 1
    
    return {
        'do_sample': True,
        'temperature': temperature,
        'top_p': top_p,
        'top_k': top_k,
        'max_new_tokens': max_tokens,
        'num_beams': num_beams,
        'early_stopping': True,
        'use_cache': True,  # å¯ç”¨KVç¼“å­˜åŠ é€Ÿ
    }

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/tts', methods=['POST'])
def text_to_speech():
    try:
        data = request.json
        text = data.get('text', '')
        mode = data.get('mode', 'voice-design')

        if not text:
            return jsonify({'success': False, 'error': 'è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬'})

        print(f"\n{'='*60}")
        print(f"ğŸ¯ è¯­éŸ³ç”Ÿæˆè¯·æ±‚ - {time.strftime('%H:%M:%S')}")
        print(f"{'='*60}")
        print(f"æ¨¡å¼: {mode}")
        print(f"æ–‡æœ¬é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # å‚æ•°æå–
        language = data.get('language', 'auto')
        language_map = {
            'zh': 'chinese', 'en': 'english', 'ja': 'japanese',
            'ko': 'korean', 'fr': 'french', 'de': 'german',
            'es': 'spanish', 'it': 'italian', 'pt': 'portuguese', 'ru': 'russian'
        }
        if language in language_map:
            language = language_map[language]
        
        voice_description = data.get('voice_description', '')
        reference_text = data.get('reference_text', '')
        speaker = data.get('speaker', 'Vivian')
        style = data.get('style', '')
        model_version = data.get('model_version', '1.7b')
        
        # è·å–å‰ç«¯ä¼ æ¥çš„æ¨¡å‹å‚æ•°
        temperature = data.get('temperature', 0.6)
        top_p = data.get('top_p', 0.85)
        
        print(f"æ¨¡å‹ç‰ˆæœ¬: {model_version}")
        print(f"è¯­è¨€: {language}")
        print(f"Temperature: {temperature}")
        print(f"Top P: {top_p}")
        
        # æ ¹æ®æ¨¡å‹ç‰ˆæœ¬å’Œæ–‡æœ¬é•¿åº¦ç”ŸæˆåŸºç¡€å‚æ•°
        text_hash = hash(text[:100])
        base_config = get_cached_generation_params(text_hash, mode, model_version, len(text))
        
        # ä½¿ç”¨å‰ç«¯ä¼ æ¥çš„å‚æ•°è¦†ç›–é»˜è®¤å€¼
        generation_config = base_config.copy()
        generation_config['temperature'] = float(temperature)
        generation_config['top_p'] = float(top_p)
        
        print(f"âš™ï¸ ç”Ÿæˆå‚æ•°: {generation_config}")
        
        # é€‰æ‹©æ¨¡å‹
        use_0_6b = (model_version == '0.6b')
        
        # å¼€å§‹è®¡æ—¶
        start_time = time.time()
        
        # æ ¹æ®æ¨¡å¼é€‰æ‹©æ¨¡å‹å’Œç”Ÿæˆæ–¹æ³•
        if mode == 'voice-design':
            if use_0_6b and model_voice_design_0_6b is not None:
                selected_model = model_voice_design_0_6b
                model_name = "0.6B VoiceDesign"
            elif model_voice_design is not None:
                selected_model = model_voice_design
                model_name = "1.7B VoiceDesign"
            else:
                raise Exception("VoiceDesignæ¨¡å‹æœªåŠ è½½")
            
            print(f"ğŸš€ ä½¿ç”¨ {model_name} ç”Ÿæˆè¯­éŸ³...")
            
            # ä½¿ç”¨torch.no_grad()åŠ é€Ÿæ¨ç†
            with torch.no_grad():
                wavs, sample_rate = selected_model.generate_voice_design(
                    text=text,
                    language=language,
                    voice_description=voice_description,
                    instruct=voice_description,
                    **generation_config
                )
                
        elif mode == 'voice-clone':
            if use_0_6b and model_base_0_6b is not None:
                selected_model = model_base_0_6b
                model_name = "0.6B Base"
            elif model_base is not None:
                selected_model = model_base
                model_name = "1.7B Base"
            else:
                raise Exception("Baseæ¨¡å‹æœªåŠ è½½")
            
            reference_audio = data.get('reference_audio', '')
            if not reference_audio:
                raise Exception("è¯·ä¸Šä¼ å‚è€ƒéŸ³é¢‘æ–‡ä»¶")
            
            ref_audio_path = os.path.join(OUTPUT_DIR, reference_audio)
            if not os.path.exists(ref_audio_path):
                ref_audio_path = os.path.join(tempfile.gettempdir(), reference_audio)
            
            print(f"ğŸš€ ä½¿ç”¨ {model_name} è¿›è¡Œå£°éŸ³å…‹éš†...")
            
            with torch.no_grad():
                try:
                    wavs, sample_rate = selected_model.generate_voice_clone(
                        text=text,
                        language=language,
                        ref_audio=ref_audio_path,
                        ref_text=reference_text if reference_text else None,
                        x_vector_only_mode=False,
                        **generation_config
                    )
                except Exception as e:
                    print(f"âš ï¸ ICLæ¨¡å¼å¤±è´¥ï¼Œåˆ‡æ¢åˆ°x_vectoræ¨¡å¼: {e}")
                    wavs, sample_rate = selected_model.generate_voice_clone(
                        text=text,
                        language=language,
                        ref_audio=ref_audio_path,
                        x_vector_only_mode=True,
                        **generation_config
                    )
                    
        elif mode == 'tts-custom':
            if use_0_6b and model_custom_voice_0_6b is not None:
                selected_model = model_custom_voice_0_6b
                model_name = "0.6B CustomVoice"
            elif model_custom_voice is not None:
                selected_model = model_custom_voice
                model_name = "1.7B CustomVoice"
            else:
                raise Exception("CustomVoiceæ¨¡å‹æœªåŠ è½½")
            
            print(f"ğŸš€ ä½¿ç”¨ {model_name} ç”Ÿæˆè¯­éŸ³...")
            
            instruct_text = style if style else None
            
            with torch.no_grad():
                if instruct_text:
                    wavs, sample_rate = selected_model.generate_custom_voice(
                        text=text,
                        language=language,
                        speaker=speaker,
                        instruct=instruct_text,
                        **generation_config
                    )
                else:
                    wavs, sample_rate = selected_model.generate_custom_voice(
                        text=text,
                        language=language,
                        speaker=speaker,
                        **generation_config
                    )
        else:
            raise Exception(f"æœªçŸ¥æ¨¡å¼: {mode}")
        
        # è®¡ç®—ç”Ÿæˆæ—¶é—´
        generation_time = time.time() - start_time
        
        # ä¿å­˜éŸ³é¢‘
        audio_data = wavs[0]
        audio_path = os.path.join(OUTPUT_DIR, f"qwen_tts_output_{int(time.time())}.wav")
        scipy.io.wavfile.write(audio_path, sample_rate, audio_data)
        
        print(f"âœ… è¯­éŸ³ç”Ÿæˆå®Œæˆï¼")
        print(f"â±ï¸ ç”Ÿæˆè€—æ—¶: {generation_time:.2f} ç§’")
        print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {audio_path}")
        print(f"{'='*60}\n")
        
        return jsonify({
            'success': True,
            'audio_url': f'/audio/{os.path.basename(audio_path)}',
            'generation_time': round(generation_time, 2),
            'sample_rate': sample_rate
        })
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)})

@app.route('/upload', methods=['POST'])
def upload_file():
    """ä¸Šä¼ å‚è€ƒéŸ³é¢‘æ–‡ä»¶"""
    try:
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æ–‡ä»¶'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'æ–‡ä»¶åä¸ºç©º'}), 400
        
        filename = f"ref_audio_{int(time.time())}_{file.filename}"
        filepath = os.path.join(OUTPUT_DIR, filename)
        file.save(filepath)
        
        print(f"ğŸ“¤ å‚è€ƒéŸ³é¢‘å·²ä¸Šä¼ : {filepath}")
        
        return jsonify({
            'success': True,
            'filename': filename,
            'filepath': filepath
        })
    except Exception as e:
        print(f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/audio/<filename>')
def serve_audio(filename):
    try:
        audio_path = os.path.join(OUTPUT_DIR, filename)
        if not os.path.exists(audio_path):
            audio_path = os.path.join(tempfile.gettempdir(), filename)
        return send_file(audio_path, mimetype='audio/wav')
    except Exception as e:
        return jsonify({'error': str(e)}), 404

if __name__ == '__main__':
    print("\n" + "="*60)
    print("ğŸš€ Qwen-TTS é«˜æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬å·²å¯åŠ¨ï¼")
    print("ğŸ“ è®¿é—®åœ°å€: http://localhost:5000")
    print("âš¡ ä¼˜åŒ–ç‰¹æ€§:")
    print("   â€¢ æ¨¡å‹åŠ¨æ€é‡åŒ– (INT8)")
    print("   â€¢ torch.compile ç¼–è¯‘åŠ é€Ÿ")
    print("   â€¢ å‚æ•°ç¼“å­˜æœºåˆ¶")
    print("   â€¢ torch.no_grad() æ¨ç†ä¼˜åŒ–")
    print("   â€¢ ä¼˜åŒ–çš„ç”Ÿæˆå‚æ•°")
    print("="*60 + "\n")
    app.run(host='0.0.0.0', port=5000, debug=False)
